"""
DOW AI - Refresh AI Context
Epoch Trading System v1 - XIII Trading LLC

Main orchestrator for weekly AI context refresh workflow.
Runs all export scripts and creates a summary report.

Usage:
    python refresh_ai_context.py              # Full refresh (JSON + Supabase)
    python refresh_ai_context.py --json-only  # Only export to JSON files
    python refresh_ai_context.py --db-only    # Only upsert to Supabase
    python refresh_ai_context.py --verbose    # Verbose output

Weekly Workflow:
    1. Run indicator edge tests (03_indicators/python/run_all_edge_tests.py)
    2. Run this script to refresh AI context
    3. Verify JSON files in ai_context/
    4. Verify Supabase tables have updated data
"""

import sys
import subprocess
import argparse
from pathlib import Path
from datetime import datetime

# Paths
SCRIPT_DIR = Path(__file__).parent
AI_CONTEXT_DIR = SCRIPT_DIR.parent / "ai_context"
LAST_UPDATED_FILE = AI_CONTEXT_DIR / "last_updated.txt"

# Export scripts
EXPORT_SCRIPTS = [
    ("Model Stats", "export_model_stats.py"),
    ("Indicator Edges", "export_indicator_edges.py"),
    ("Zone Performance", "export_zone_performance.py"),
]


def run_export_script(name: str, script_name: str, args: argparse.Namespace) -> bool:
    """Run a single export script and return success status."""
    script_path = SCRIPT_DIR / script_name

    if not script_path.exists():
        print(f"    ERROR: Script not found: {script_path}")
        return False

    # Build command
    cmd = [sys.executable, str(script_path)]

    if args.json_only:
        cmd.append('--json-only')
    if args.db_only:
        cmd.append('--db-only')
    if args.verbose:
        cmd.append('--verbose')

    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=120  # 2 minute timeout per script
        )

        if result.returncode == 0:
            if args.verbose:
                # Print script output indented
                for line in result.stdout.strip().split('\n'):
                    print(f"    {line}")
            return True
        else:
            print(f"    ERROR: {script_name} failed with return code {result.returncode}")
            if result.stderr:
                print(f"    STDERR: {result.stderr[:500]}")
            return False

    except subprocess.TimeoutExpired:
        print(f"    ERROR: {script_name} timed out after 120 seconds")
        return False
    except Exception as e:
        print(f"    ERROR: Failed to run {script_name}: {e}")
        return False


def update_last_updated_file():
    """Write timestamp to last_updated.txt."""
    try:
        AI_CONTEXT_DIR.mkdir(parents=True, exist_ok=True)
        with open(LAST_UPDATED_FILE, 'w') as f:
            f.write(f"Last updated: {datetime.now().isoformat()}\n")
            f.write(f"Generated by: refresh_ai_context.py\n")
        return True
    except Exception as e:
        print(f"  WARNING: Could not update last_updated.txt: {e}")
        return False


def verify_json_files(verbose: bool = False) -> dict:
    """Verify that all expected JSON files exist and have content."""
    expected_files = [
        "model_stats.json",
        "indicator_edges.json",
        "zone_performance.json"
    ]

    results = {}
    for filename in expected_files:
        filepath = AI_CONTEXT_DIR / filename
        if filepath.exists():
            size = filepath.stat().st_size
            results[filename] = {'exists': True, 'size': size}
            if verbose:
                print(f"    {filename}: {size:,} bytes")
        else:
            results[filename] = {'exists': False, 'size': 0}
            if verbose:
                print(f"    {filename}: MISSING")

    return results


def main():
    parser = argparse.ArgumentParser(
        description='Refresh DOW AI context data from Supabase and indicator edge tests',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
    python refresh_ai_context.py              # Full refresh
    python refresh_ai_context.py --json-only  # Only update local JSON files
    python refresh_ai_context.py --verbose    # Show detailed output

Weekly Workflow:
    1. Run indicator edge tests: python run_all_edge_tests.py
    2. Run this script: python refresh_ai_context.py
    3. Verify output in ai_context/ directory
        """
    )
    parser.add_argument('--json-only', action='store_true',
                        help='Only export to JSON, skip Supabase uploads')
    parser.add_argument('--db-only', action='store_true',
                        help='Only upsert to Supabase, skip JSON exports')
    parser.add_argument('--verbose', '-v', action='store_true',
                        help='Verbose output')
    args = parser.parse_args()

    start_time = datetime.now()

    print("=" * 70)
    print("DOW AI - Refresh AI Context")
    print("=" * 70)
    print(f"\nStarted: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")

    if args.json_only:
        print("Mode: JSON export only (skipping Supabase)")
    elif args.db_only:
        print("Mode: Supabase upload only (skipping JSON)")
    else:
        print("Mode: Full refresh (JSON + Supabase)")

    # Run each export script
    results = {}
    print("\n" + "-" * 70)

    for i, (name, script) in enumerate(EXPORT_SCRIPTS, 1):
        print(f"\n[{i}/{len(EXPORT_SCRIPTS)}] Running {name}...")
        success = run_export_script(name, script, args)
        results[name] = success
        print(f"  {'SUCCESS' if success else 'FAILED'}")

    # Update timestamp file
    print("\n" + "-" * 70)
    print("\n[4/4] Updating timestamp...")
    if not args.db_only:
        update_last_updated_file()
        print("  SUCCESS")
    else:
        print("  SKIPPED (db-only mode)")

    # Verify JSON files
    if not args.db_only:
        print("\n" + "-" * 70)
        print("\nVerifying JSON files:")
        file_results = verify_json_files(verbose=True)
        all_exist = all(f['exists'] for f in file_results.values())
        print(f"\n  All files present: {'YES' if all_exist else 'NO'}")

    # Summary
    print("\n" + "=" * 70)
    print("SUMMARY")
    print("=" * 70)

    success_count = sum(1 for v in results.values() if v)
    total_count = len(results)

    print(f"\nExport Results: {success_count}/{total_count} successful")
    for name, success in results.items():
        status = "OK" if success else "FAILED"
        print(f"  - {name}: {status}")

    elapsed = (datetime.now() - start_time).total_seconds()
    print(f"\nDuration: {elapsed:.1f} seconds")
    print(f"Completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    if not args.db_only:
        print(f"\nJSON files location: {AI_CONTEXT_DIR}")

    print("\n" + "=" * 70)

    # Exit with error code if any failures
    if success_count < total_count:
        sys.exit(1)


if __name__ == '__main__':
    main()
