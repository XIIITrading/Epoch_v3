================================================================================
EPOCH TRADE REVIEW SYSTEM - IMPLEMENTATION SPECIFICATION
Version: 1.0
Purpose: Claude Code Implementation Guide
================================================================================

OVERVIEW
--------
Build a Streamlit-based trade review system designed for deliberate practice of 
right-edge trading decisions. The system presents trades in "flashcard" format 
where the user evaluates setups BEFORE seeing outcomes, building calibrated 
intuition over hundreds of repetitions.

The user already has:
- Working Streamlit app with Polygon integration
- Zone rendering system
- Pre-market visualization
- Trade data in Supabase (Entry, Exit, MFE, MAE, statistics per trade)
- Monte Carlo simulation output

CRITICAL: Before implementing, review the existing codebase to understand:
1. Current Polygon client implementation and authentication
2. Zone data structure and rendering approach
3. Existing Streamlit patterns and session state usage
4. Supabase schema for trades table


================================================================================
SECTION 1: CORE ARCHITECTURE
================================================================================

1.1 PROJECT STRUCTURE
---------------------
epoch_review/
â”œâ”€â”€ app.py                      # Main Streamlit entry point
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ charts.py               # Plotly multi-timeframe chart builder
â”‚   â”œâ”€â”€ flashcard_flow.py       # Evaluate â†’ Reveal state machine
â”‚   â”œâ”€â”€ navigation.py           # Trade queue navigation
â”‚   â”œâ”€â”€ stats_panel.py          # Trade statistics display
â”‚   â””â”€â”€ calibration_tracker.py  # Performance metrics on user reads
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ polygon_client.py       # ADAPT FROM EXISTING - bar data fetching
â”‚   â”œâ”€â”€ supabase_client.py      # Trade + review CRUD operations
â”‚   â””â”€â”€ cache_manager.py        # Daily bar caching, prefetch logic
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ trade.py                # Trade dataclass
â”‚   â””â”€â”€ review.py               # Review/assessment dataclass
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ time_utils.py           # ET timezone handling, market hours
â”‚   â””â”€â”€ chart_helpers.py        # Annotation builders, zone shapes
â””â”€â”€ config.py                   # API keys, display settings, constants


1.2 DATA FLOW
-------------
INITIALIZATION:
1. Fetch trade list from Supabase (lightweight metadata only)
2. Apply user filters (date range, model, reviewed/unreviewed)
3. Shuffle queue (prevents temporal memory leakage)
4. Initialize cache manager
5. Fetch daily bars for first trade's symbol/date (single Polygon call)
6. Prefetch bars for next 3 unique symbol/date combinations

REVIEW LOOP:
1. Display current trade in EVALUATE mode (right-edge charts)
2. User commits assessment (Strong/Weak/No Trade)
3. Transition to REVEAL mode (extended charts + outcome)
4. User adds optional notes
5. Write review to Supabase
6. Advance to next trade, reset to EVALUATE mode
7. Trigger prefetch for upcoming trades

KEY OPTIMIZATION:
- Polygon data is fetched ONCE per symbol/date combination
- Multiple trades on same symbol/date reuse cached bars
- Only slice differently based on entry/exit times
- Expect ~10 tickers per day max (per user's note)


================================================================================
SECTION 2: FLASHCARD SYSTEM DESIGN
================================================================================

2.1 EVALUATE MODE (Right-Edge View)
-----------------------------------
Purpose: Recreate the information state at decision time

Charts display:
- 5-minute: 120 candles ending at entry bar (configurable)
- 15-minute: 120 candles ending at entry bar
- 1-hour: 120 candles ending at entry bar

Visible elements:
- All zone levels (from existing zone system)
- Entry marker (vertical line or arrow) on 5-minute chart
- Current price at entry time

HIDDEN elements:
- Exit marker
- Outcome statistics (P&L, MFE, MAE)
- Any candles after entry

User action required:
- Must select assessment before proceeding
- Options: [Strong Setup] [Weak Setup] [No Trade]
- Keyboard shortcuts: A, B, C respectively

2.2 REVEAL MODE (Full View)
---------------------------
Purpose: Show what actually happened for learning

Charts display:
- All timeframes extended to show entry â†’ exit
- Entry marker (green vertical line)
- Exit marker (red vertical line)
- Trade duration visible in price action

Visible elements:
- Complete outcome statistics
- MFE (Maximum Favorable Excursion)
- MAE (Maximum Adverse Excursion)
- Final P&L in R-multiple
- User's pre-reveal assessment
- Correct/Incorrect feedback

User actions available:
- Add notes (free text)
- Proceed to next trade
- Keyboard: N for notes focus, â†’ or SPACE for next trade

2.3 STATE MACHINE
-----------------
States:
- EVALUATE: Awaiting user assessment
- REVEAL: Showing outcome, awaiting navigation

Transitions:
- EVALUATE â†’ REVEAL: User selects assessment (A/B/C)
- REVEAL â†’ EVALUATE: User advances to next trade

Session state keys:
- current_trade_index: int
- reveal_state: 'evaluate' | 'reveal'
- user_read: 'strong' | 'weak' | 'no_trade' | None
- review_queue: list[Trade]
- daily_bars_cache: dict[str, dict[str, pd.DataFrame]]


================================================================================
SECTION 3: COMPONENT SPECIFICATIONS
================================================================================

3.1 charts.py - Multi-Timeframe Chart Builder
---------------------------------------------
INTEGRATE WITH EXISTING ZONE RENDERING SYSTEM

Primary function:
```python
def build_review_chart(
    bars_5m: pd.DataFrame,
    bars_15m: pd.DataFrame,
    bars_1h: pd.DataFrame,
    zones: list[Zone],           # Use existing Zone model
    entry_time: datetime,
    exit_time: datetime | None,  # None in evaluate mode
    mode: str,                   # 'evaluate' or 'reveal'
    config: ChartConfig
) -> go.Figure:
    """
    Returns Plotly figure with 3 vertically stacked subplots.
    
    Layout:
    - Row 1 (top): 1-hour candles - market context
    - Row 2 (middle): 15-minute candles - structure
    - Row 3 (bottom): 5-minute candles - execution detail
    
    Zone rendering: Adapt existing zone drawing logic
    Entry/Exit: Vertical lines with annotations
    """
```

Chart configuration defaults:
```python
CHART_CONFIG = {
    'candle_count': 120,
    'row_heights': [0.25, 0.35, 0.40],  # 1h smallest, 5m largest
    'zone_opacity': 0.15,
    'zone_border_width': 1,
    'entry_color': '#00C853',      # Green
    'entry_line_width': 2,
    'entry_line_dash': 'solid',
    'exit_color': '#FF1744',       # Red
    'exit_line_width': 2,
    'exit_line_dash': 'dash',
    'chart_height': 900,           # Total figure height in pixels
    'background_color': '#131722', # Dark theme (TradingView style)
    'grid_color': '#1e222d',
    'candle_up_color': '#26a69a',
    'candle_down_color': '#ef5350',
}
```

Plotly implementation notes:
- Use make_subplots(rows=3, cols=1, shared_xaxes=False, row_heights=[...])
- Each subplot gets independent x-axis (different timeframes)
- Zones: fig.add_shape(type="rect", ...) for each zone
- Entry/Exit: fig.add_vline(x=timestamp, ...) with annotation
- Hide rangeslider: fig.update_xaxes(rangeslider_visible=False)
- Dark theme: fig.update_layout(template="plotly_dark", ...)


3.2 flashcard_flow.py - State Machine Controller
------------------------------------------------
```python
def render_flashcard_ui(
    trade: Trade,
    bars: dict[str, pd.DataFrame],  # {'5m': df, '15m': df, '1h': df}
    zones: list[Zone],
    supabase_client: SupabaseClient
) -> None:
    """
    Manages the evaluate â†’ reveal flow for a single trade.
    
    Handles:
    - State transitions based on user input
    - Assessment capture before reveal
    - Review persistence to Supabase
    - Keyboard shortcut handling
    """
    
    # Initialize state
    if 'reveal_state' not in st.session_state:
        st.session_state.reveal_state = 'evaluate'
        st.session_state.user_read = None
    
    if st.session_state.reveal_state == 'evaluate':
        _render_evaluate_mode(trade, bars, zones)
    else:
        _render_reveal_mode(trade, bars, zones, supabase_client)


def _render_evaluate_mode(trade, bars, zones):
    """Right-edge view with assessment buttons."""
    
    # Slice bars to entry point
    sliced_bars = {
        tf: slice_to_entry(df, trade.entry_time)
        for tf, df in bars.items()
    }
    
    # Build and display chart
    fig = build_review_chart(
        sliced_bars['5m'],
        sliced_bars['15m'],
        sliced_bars['1h'],
        zones,
        entry_time=trade.entry_time,
        exit_time=None,  # Hidden in evaluate mode
        mode='evaluate',
        config=CHART_CONFIG
    )
    st.plotly_chart(fig, use_container_width=True, key='eval_chart')
    
    # Assessment buttons
    st.markdown("### What's your read on this setup?")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ðŸŸ¢ Strong Setup (A)", use_container_width=True):
            st.session_state.user_read = 'strong'
            st.session_state.reveal_state = 'reveal'
            st.rerun()
    
    with col2:
        if st.button("ðŸŸ¡ Weak Setup (B)", use_container_width=True):
            st.session_state.user_read = 'weak'
            st.session_state.reveal_state = 'reveal'
            st.rerun()
    
    with col3:
        if st.button("ðŸ”´ No Trade (C)", use_container_width=True):
            st.session_state.user_read = 'no_trade'
            st.session_state.reveal_state = 'reveal'
            st.rerun()


def _render_reveal_mode(trade, bars, zones, supabase_client):
    """Full view with outcome and feedback."""
    
    # Slice bars through exit
    sliced_bars = {
        tf: slice_to_exit(df, trade.exit_time)
        for tf, df in bars.items()
    }
    
    # Build and display chart
    fig = build_review_chart(
        sliced_bars['5m'],
        sliced_bars['15m'],
        sliced_bars['1h'],
        zones,
        entry_time=trade.entry_time,
        exit_time=trade.exit_time,
        mode='reveal',
        config=CHART_CONFIG
    )
    st.plotly_chart(fig, use_container_width=True, key='reveal_chart')
    
    # Outcome feedback
    render_outcome_feedback(trade, st.session_state.user_read)
    
    # Stats panel
    render_stats_panel(trade)
    
    # Notes input
    notes = st.text_area("Notes on this trade:", key='trade_notes')
    
    # Save and advance
    col1, col2 = st.columns([1, 3])
    with col2:
        if st.button("Next Trade â†’", use_container_width=True):
            # Persist review
            save_review(
                supabase_client,
                trade_id=trade.id,
                user_read=st.session_state.user_read,
                notes=notes
            )
            # Advance
            advance_to_next_trade()
            st.session_state.reveal_state = 'evaluate'
            st.session_state.user_read = None
            st.rerun()
```


3.3 cache_manager.py - Performance Optimization
-----------------------------------------------
```python
class BarCache:
    """
    Manages Polygon bar data with daily caching strategy.
    
    Key insight: User reviews ~10 tickers/day max.
    Fetch full day once per symbol, slice per trade.
    """
    
    def __init__(self, polygon_client):
        self.polygon = polygon_client
        # Cache key: f"{symbol}_{date}_{timeframe}"
        # Stored in st.session_state for persistence
    
    def get_bars_for_trade(
        self,
        symbol: str,
        trade_date: date,
        entry_time: datetime,
        exit_time: datetime,
        candle_count: int = 120
    ) -> dict[str, pd.DataFrame]:
        """
        Returns {'5m': df, '15m': df, '1h': df} for a trade.
        Uses cached daily data when available.
        """
        result = {}
        for timeframe in ['5m', '15m', '1h']:
            cache_key = f"{symbol}_{trade_date}_{timeframe}"
            
            if cache_key not in st.session_state.bar_cache:
                # Fetch full day from Polygon
                daily_bars = self._fetch_daily_bars(
                    symbol, trade_date, timeframe
                )
                st.session_state.bar_cache[cache_key] = daily_bars
            
            result[timeframe] = st.session_state.bar_cache[cache_key]
        
        return result
    
    def _fetch_daily_bars(
        self,
        symbol: str,
        trade_date: date,
        timeframe: str
    ) -> pd.DataFrame:
        """
        Fetch bars from market open (08:00 ET) to close (20:00 ET).
        ADAPT FROM EXISTING POLYGON CLIENT.
        
        Polygon API call:
        /v2/aggs/ticker/{symbol}/range/{multiplier}/{timespan}/{from}/{to}
        
        Timeframe mapping:
        - '5m' â†’ multiplier=5, timespan='minute'
        - '15m' â†’ multiplier=15, timespan='minute'
        - '1h' â†’ multiplier=1, timespan='hour'
        """
        pass  # Implement using existing polygon_client
    
    def prefetch_for_trades(self, upcoming_trades: list[Trade]):
        """
        Background fetch for upcoming trades.
        Identifies unique symbol/date combinations and fetches.
        """
        seen = set()
        for trade in upcoming_trades:
            key = (trade.symbol, trade.trade_date)
            if key not in seen:
                seen.add(key)
                # Trigger fetch for all timeframes
                self.get_bars_for_trade(
                    trade.symbol,
                    trade.trade_date,
                    trade.entry_time,
                    trade.exit_time
                )
```


3.4 stats_panel.py - Trade Statistics Display
---------------------------------------------
```python
def render_stats_panel(trade: Trade):
    """
    Display trade statistics in a clean, readable format.
    Only shown in REVEAL mode.
    """
    
    st.markdown("---")
    st.markdown("### Trade Statistics")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="P&L",
            value=f"{trade.pnl_r:+.2f}R",
            delta=None
        )
    
    with col2:
        st.metric(
            label="MFE",
            value=f"+{trade.mfe_r:.2f}R",
            help="Maximum Favorable Excursion"
        )
    
    with col3:
        st.metric(
            label="MAE",
            value=f"-{trade.mae_r:.2f}R",
            help="Maximum Adverse Excursion"
        )
    
    with col4:
        st.metric(
            label="Duration",
            value=format_duration(trade.entry_time, trade.exit_time)
        )
    
    # Additional details in expander
    with st.expander("Full Trade Details"):
        details_col1, details_col2 = st.columns(2)
        
        with details_col1:
            st.write(f"**Model:** {trade.model}")
            st.write(f"**Symbol:** {trade.symbol}")
            st.write(f"**Direction:** {trade.direction}")
        
        with details_col2:
            st.write(f"**Entry Time:** {trade.entry_time.strftime('%H:%M:%S ET')}")
            st.write(f"**Exit Time:** {trade.exit_time.strftime('%H:%M:%S ET')}")
            st.write(f"**Entry Price:** ${trade.entry_price:.2f}")
            st.write(f"**Exit Price:** ${trade.exit_price:.2f}")
```


3.5 calibration_tracker.py - Performance Analytics
--------------------------------------------------
```python
def render_calibration_metrics(supabase_client, user_id: str):
    """
    Display running accuracy metrics on user's setup reads.
    Shows in sidebar or dedicated analytics page.
    """
    
    reviews = fetch_all_reviews(supabase_client, user_id)
    
    if not reviews:
        st.info("Complete some trade reviews to see calibration metrics.")
        return
    
    # Calculate accuracy by read type
    metrics = calculate_calibration(reviews)
    
    st.markdown("### Your Calibration")
    
    # Strong setup accuracy
    st.markdown("**'Strong Setup' calls:**")
    strong_acc = metrics['strong']['accuracy']
    st.progress(strong_acc)
    st.caption(
        f"{metrics['strong']['correct']}/{metrics['strong']['total']} "
        f"were winners ({strong_acc:.0%})"
    )
    
    # Weak setup accuracy
    st.markdown("**'Weak Setup' calls:**")
    weak_acc = metrics['weak']['accuracy']
    st.progress(weak_acc)
    st.caption(
        f"{metrics['weak']['correct']}/{metrics['weak']['total']} "
        f"were losers ({weak_acc:.0%})"
    )
    
    # No trade accuracy
    st.markdown("**'No Trade' calls:**")
    no_trade_acc = metrics['no_trade']['accuracy']
    st.progress(no_trade_acc)
    st.caption(
        f"{metrics['no_trade']['correct']}/{metrics['no_trade']['total']} "
        f"were correct to skip ({no_trade_acc:.0%})"
    )


def calculate_calibration(reviews: list[Review]) -> dict:
    """
    Determine accuracy of each read type.
    
    Correct definitions:
    - 'strong' is correct if trade was a winner (P&L > 0)
    - 'weak' is correct if trade was a loser (P&L < 0)
    - 'no_trade' is correct if trade was a loser or breakeven
    """
    results = {
        'strong': {'correct': 0, 'total': 0, 'accuracy': 0},
        'weak': {'correct': 0, 'total': 0, 'accuracy': 0},
        'no_trade': {'correct': 0, 'total': 0, 'accuracy': 0},
    }
    
    for review in reviews:
        read = review.user_read
        results[read]['total'] += 1
        
        if read == 'strong' and review.trade.pnl_r > 0:
            results[read]['correct'] += 1
        elif read == 'weak' and review.trade.pnl_r < 0:
            results[read]['correct'] += 1
        elif read == 'no_trade' and review.trade.pnl_r <= 0:
            results[read]['correct'] += 1
    
    for read in results:
        if results[read]['total'] > 0:
            results[read]['accuracy'] = (
                results[read]['correct'] / results[read]['total']
            )
    
    return results
```


================================================================================
SECTION 4: DATA MODELS
================================================================================

4.1 Trade Model
---------------
```python
from dataclasses import dataclass
from datetime import datetime, date
from typing import Optional

@dataclass
class Trade:
    """
    Trade record from Supabase.
    VERIFY FIELD NAMES MATCH EXISTING SCHEMA.
    """
    id: str                      # UUID
    symbol: str
    trade_date: date
    model: str                   # Trading model/strategy name
    direction: str               # 'long' or 'short'
    
    entry_time: datetime
    entry_price: float
    
    exit_time: datetime
    exit_price: float
    
    # Statistics (from Monte Carlo output)
    pnl_r: float                 # P&L in R-multiples
    mfe_r: float                 # Max Favorable Excursion in R
    mae_r: float                 # Max Adverse Excursion in R
    
    # Optional metadata
    zone_id: Optional[str] = None
    notes: Optional[str] = None
```


4.2 Review Model
----------------
```python
@dataclass
class Review:
    """Review/assessment record."""
    id: str
    trade_id: str
    trade: Trade                 # Joined for convenience
    
    user_read: str               # 'strong', 'weak', 'no_trade'
    actual_outcome: str          # 'winner', 'loser', 'breakeven'
    read_correct: bool
    
    notes: Optional[str]
    reviewed_at: datetime
```


4.3 Zone Model
--------------
```python
@dataclass
class Zone:
    """
    ADAPT FROM EXISTING ZONE IMPLEMENTATION.
    Include whatever fields your current system uses.
    """
    id: str
    symbol: str
    price_high: float
    price_low: float
    zone_type: str               # e.g., 'supply', 'demand', 'pivot'
    timeframe: str               # e.g., '1h', '4h', 'daily'
    color: str                   # Hex color for rendering
    # ... additional fields from your existing model
```


================================================================================
SECTION 5: SUPABASE SCHEMA
================================================================================

5.1 New Table: trade_reviews
----------------------------
```sql
-- Store user assessments and track calibration

create table trade_reviews (
    id uuid primary key default gen_random_uuid(),
    trade_id uuid references trades(id) on delete cascade,
    
    -- Pre-reveal assessment
    user_read text not null check (user_read in ('strong', 'weak', 'no_trade')),
    
    -- Outcome classification (set on insert based on trade P&L)
    actual_outcome text not null check (actual_outcome in ('winner', 'loser', 'breakeven')),
    
    -- Computed correctness
    read_correct boolean generated always as (
        case 
            when user_read = 'strong' and actual_outcome = 'winner' then true
            when user_read = 'weak' and actual_outcome = 'loser' then true
            when user_read = 'no_trade' and actual_outcome in ('loser', 'breakeven') then true
            else false
        end
    ) stored,
    
    -- User notes
    notes text,
    
    -- Timestamps
    reviewed_at timestamp with time zone default now(),
    created_at timestamp with time zone default now(),
    
    -- Prevent duplicate reviews
    unique(trade_id)
);

-- Indexes
create index idx_trade_reviews_user_read on trade_reviews(user_read);
create index idx_trade_reviews_read_correct on trade_reviews(read_correct);
create index idx_trade_reviews_reviewed_at on trade_reviews(reviewed_at);
```


5.2 View: unreviewed_trades
---------------------------
```sql
-- Convenience view for fetching trades that haven't been reviewed

create view unreviewed_trades as
select t.*
from trades t
left join trade_reviews r on t.id = r.trade_id
where r.id is null;
```


5.3 Function: get_calibration_stats
-----------------------------------
```sql
-- Server-side aggregation for calibration metrics

create or replace function get_calibration_stats()
returns table (
    user_read text,
    total_count bigint,
    correct_count bigint,
    accuracy numeric
) as $$
begin
    return query
    select 
        r.user_read,
        count(*) as total_count,
        count(*) filter (where r.read_correct) as correct_count,
        round(
            count(*) filter (where r.read_correct)::numeric / count(*)::numeric,
            3
        ) as accuracy
    from trade_reviews r
    group by r.user_read;
end;
$$ language plpgsql;
```


================================================================================
SECTION 6: MAIN APPLICATION
================================================================================

6.1 app.py - Entry Point
------------------------
```python
import streamlit as st
import random
from config import CHART_CONFIG
from data.supabase_client import get_supabase_client
from data.polygon_client import get_polygon_client  # EXISTING
from data.cache_manager import BarCache
from components.flashcard_flow import render_flashcard_ui
from components.navigation import render_sidebar_filters, render_trade_counter
from components.calibration_tracker import render_calibration_metrics

def main():
    st.set_page_config(
        page_title="Epoch Trade Review",
        page_icon="ðŸ“Š",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # Initialize clients
    supabase = get_supabase_client()
    polygon = get_polygon_client()  # Your existing implementation
    
    # Initialize cache in session state
    if 'bar_cache' not in st.session_state:
        st.session_state.bar_cache = {}
    
    cache = BarCache(polygon)
    
    # Sidebar
    with st.sidebar:
        st.title("Epoch Review")
        st.markdown("---")
        
        # Filters
        filters = render_sidebar_filters()
        
        # Fetch and shuffle trade queue
        if 'review_queue' not in st.session_state or st.sidebar.button("Refresh Queue"):
            trades = fetch_trades(supabase, filters)
            random.shuffle(trades)  # Prevent temporal memory leakage
            st.session_state.review_queue = trades
            st.session_state.current_trade_index = 0
        
        queue = st.session_state.review_queue
        
        # Queue info
        st.markdown("---")
        st.metric("Trades in Queue", len(queue))
        
        reviewed_count = st.session_state.get('current_trade_index', 0)
        st.progress(reviewed_count / len(queue) if queue else 0)
        st.caption(f"{reviewed_count} of {len(queue)} reviewed this session")
        
        # Calibration metrics
        st.markdown("---")
        render_calibration_metrics(supabase, user_id="current_user")
    
    # Main content
    if not queue:
        st.info("No trades to review. Adjust filters or check back after running your screener.")
        return
    
    current_idx = st.session_state.current_trade_index
    
    if current_idx >= len(queue):
        st.success("ðŸŽ‰ You've reviewed all trades in this queue!")
        if st.button("Start Over"):
            st.session_state.current_trade_index = 0
            st.rerun()
        return
    
    current_trade = queue[current_idx]
    
    # Trade counter header
    render_trade_counter(current_idx, len(queue), current_trade)
    
    # Fetch bars (cached)
    bars = cache.get_bars_for_trade(
        symbol=current_trade.symbol,
        trade_date=current_trade.trade_date,
        entry_time=current_trade.entry_time,
        exit_time=current_trade.exit_time,
        candle_count=CHART_CONFIG['candle_count']
    )
    
    # Fetch zones for this trade
    zones = fetch_zones_for_symbol(supabase, current_trade.symbol, current_trade.trade_date)
    
    # Render flashcard UI (handles evaluate/reveal flow)
    render_flashcard_ui(current_trade, bars, zones, supabase)
    
    # Prefetch upcoming trades
    if current_idx + 1 < len(queue):
        upcoming = queue[current_idx + 1 : current_idx + 4]
        cache.prefetch_for_trades(upcoming)


def fetch_trades(supabase, filters) -> list[Trade]:
    """
    Fetch trades from Supabase based on filters.
    ADAPT QUERY TO MATCH YOUR EXISTING SCHEMA.
    """
    query = supabase.table('trades').select('*')
    
    if filters.get('date_from'):
        query = query.gte('trade_date', filters['date_from'])
    if filters.get('date_to'):
        query = query.lte('trade_date', filters['date_to'])
    if filters.get('model'):
        query = query.eq('model', filters['model'])
    if filters.get('unreviewed_only'):
        # Use the unreviewed_trades view instead
        query = supabase.table('unreviewed_trades').select('*')
    
    result = query.execute()
    return [Trade(**row) for row in result.data]


def fetch_zones_for_symbol(supabase, symbol: str, trade_date: date) -> list[Zone]:
    """
    Fetch zones relevant to this symbol/date.
    ADAPT TO MATCH YOUR EXISTING ZONE QUERY.
    """
    # Your existing zone fetch logic
    pass


if __name__ == "__main__":
    main()
```


================================================================================
SECTION 7: EXISTING CODE INTEGRATION
================================================================================

IMPORTANT: Before implementing, Claude Code should review the existing codebase.

7.1 Files to Review
-------------------
[TO BE IDENTIFIED FROM USER'S CODEBASE]

Key areas to understand:
1. Polygon client initialization and authentication method
2. Bar data fetch function signature and return format
3. Zone data structure and storage
4. Existing Streamlit session state patterns
5. Supabase client setup and query patterns
6. Any existing charting code (Plotly/mplfinance/etc.)

7.2 Integration Points
----------------------
The new system should:
- REUSE the existing Polygon client (don't create a new one)
- REUSE the existing zone rendering logic where possible
- FOLLOW the same patterns for Supabase queries
- MAINTAIN consistency with existing code style

7.3 Questions for User
----------------------
During implementation, clarify:
1. What is the exact Supabase schema for the trades table?
2. How are zones currently stored and queried?
3. Are there any existing chart components to build upon?
4. What timezone handling is already in place?


================================================================================
SECTION 8: CONFIGURATION
================================================================================

8.1 config.py
-------------
```python
import os
from datetime import time

# API Configuration
POLYGON_API_KEY = os.getenv("POLYGON_API_KEY")
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

# Market Hours (Eastern Time)
MARKET_OPEN = time(8, 0)   # 08:00 ET for pre-market
MARKET_CLOSE = time(20, 0) # 20:00 ET for after-hours

# Chart Configuration
CHART_CONFIG = {
    'candle_count': 120,
    'row_heights': [0.25, 0.35, 0.40],
    'zone_opacity': 0.15,
    'zone_border_width': 1,
    'entry_color': '#00C853',
    'entry_line_width': 2,
    'exit_color': '#FF1744',
    'exit_line_width': 2,
    'chart_height': 900,
    'background_color': '#131722',
    'grid_color': '#1e222d',
    'candle_up_color': '#26a69a',
    'candle_down_color': '#ef5350',
}

# Cache Configuration
PREFETCH_COUNT = 3
BAR_CACHE_TTL_SECONDS = 3600  # 1 hour

# Review Configuration
DEFAULT_FILTERS = {
    'unreviewed_only': True,
    'date_from': None,  # Will default to last 7 days in UI
    'date_to': None,
    'model': None,
}
```


================================================================================
SECTION 9: IMPLEMENTATION ORDER
================================================================================

Phase 1: Core Infrastructure (Day 1)
------------------------------------
1. Review existing codebase (Polygon client, zones, Supabase schema)
2. Create project structure
3. Implement config.py with existing credentials
4. Implement cache_manager.py with daily bar caching
5. Test: Verify bar fetching and caching works

Phase 2: Chart Building (Day 2)
-------------------------------
1. Implement charts.py with multi-timeframe layout
2. Integrate existing zone rendering
3. Add entry/exit markers
4. Test: Render a single trade in both modes

Phase 3: Flashcard Flow (Day 3)
-------------------------------
1. Implement flashcard_flow.py state machine
2. Create stats_panel.py
3. Set up Supabase trade_reviews table
4. Test: Complete evaluate â†’ reveal flow for one trade

Phase 4: Navigation & Queue (Day 4)
-----------------------------------
1. Implement navigation.py with filters
2. Wire up main app.py
3. Add queue shuffling
4. Test: Review multiple trades in sequence

Phase 5: Calibration & Polish (Day 5)
-------------------------------------
1. Implement calibration_tracker.py
2. Add keyboard shortcuts (stretch goal)
3. Performance testing with real data volume
4. Bug fixes and UI polish


================================================================================
SECTION 10: TESTING CHECKLIST
================================================================================

[ ] Bar data fetches correctly from Polygon
[ ] Cache prevents duplicate API calls for same symbol/date
[ ] Charts render correctly in both evaluate and reveal modes
[ ] Zones display properly on all timeframes
[ ] Entry marker shows on evaluate mode
[ ] Exit marker only shows on reveal mode
[ ] Assessment buttons transition to reveal mode
[ ] Review persists to Supabase
[ ] Next trade advances correctly
[ ] Queue shuffles on load
[ ] Filters work correctly
[ ] Calibration metrics calculate accurately
[ ] Prefetch triggers for upcoming trades
[ ] No excessive rerenders or performance issues


================================================================================
END OF SPECIFICATION
================================================================================