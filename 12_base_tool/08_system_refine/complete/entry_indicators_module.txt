# ENTRY INDICATORS MODULE CREATION
## Claude Code Implementation Instructions
### Epoch Trading System - Entry Indicators Data Foundation

**Document Version:** 1.0  
**Created:** 2026-01-03  
**Author:** Monte AI / Silva  
**Target Application:** 12_indicator_analysis  

---

## 1. OBJECTIVE

Create the `entry_indicators` table and population module that captures accurate indicator snapshots at trade entry time. This is the data foundation for CALC-005 through CALC-008.

### Core Approach
- Use M1 bar close prior to entry as the indicator calculation point
- Calculate indicators on M5+ aggregated timeframes (matching DOW AI logic)
- Reuse M1 data already fetched for MFE/MAE calculations where possible
- Batch Polygon API calls by ticker-date for efficiency

---

## 2. PROJECT CONTEXT

### Directory Structure
```
C:\XIIITradingSystems\Epoch\02_zone_system\12_indicator_analysis\
├── calculations/
│   ├── trade_management/
│   │   ├── mfe_mae_stats.py        # Reference pattern
│   │   ├── mfe_mae_sequence.py     # Reference pattern
│   │   └── simulated_outcomes.py   # Reference pattern
│   └── indicator_analysis/
│       ├── __init__.py
│       └── entry_indicators/        # NEW SUBDIRECTORY
│           ├── __init__.py
│           ├── table_schema.py      # SQL schema definition
│           ├── calculator.py        # Indicator calculation logic
│           ├── populator.py         # Database population logic
│           └── runner.py            # CLI entry point
├── calculations/
│   └── indicators/                  # EXISTING - Reference for calculations
│       ├── sma.py
│       ├── vwap.py
│       ├── volume_roc.py
│       ├── volume_delta.py
│       └── cvd.py
├── calculations/
│   └── structure/                   # EXISTING - Reference for structure
│       ├── m5_structure.py
│       ├── m15_structure.py
│       ├── h1_structure.py
│       └── h4_structure.py
└── calculations/
    └── health/                      # EXISTING - Reference for health score
        └── health_score.py
```

---

## 3. DATABASE TABLE SCHEMA

### File: calculations/indicator_analysis/entry_indicators/table_schema.py

```python
"""
Entry Indicators Table Schema

SQL schema definition for the entry_indicators table.
Run create_table() to create the table in Supabase.
"""

CREATE_TABLE_SQL = """
CREATE TABLE IF NOT EXISTS public.entry_indicators (
  -- Primary Key & Foreign Key
  trade_id VARCHAR(50) NOT NULL,
  
  -- Trade Context (denormalized for query performance)
  date DATE NOT NULL,
  ticker VARCHAR(10) NOT NULL,
  direction VARCHAR(10) NOT NULL,
  model VARCHAR(10) NULL,
  entry_time TIME WITHOUT TIME ZONE NOT NULL,
  entry_price NUMERIC(12, 4) NOT NULL,
  
  -- Indicator Bar Reference
  indicator_bar_time TIME WITHOUT TIME ZONE NULL,
  indicator_methodology VARCHAR(20) DEFAULT 'M1_PRIOR',
  
  -- STRUCTURE FACTORS (4 points possible)
  h4_structure VARCHAR(10) NULL,
  h4_structure_healthy BOOLEAN NULL,
  h1_structure VARCHAR(10) NULL,
  h1_structure_healthy BOOLEAN NULL,
  m15_structure VARCHAR(10) NULL,
  m15_structure_healthy BOOLEAN NULL,
  m5_structure VARCHAR(10) NULL,
  m5_structure_healthy BOOLEAN NULL,
  
  -- VOLUME FACTORS (3 points possible)
  vol_roc NUMERIC(10, 4) NULL,
  vol_roc_healthy BOOLEAN NULL,
  vol_delta NUMERIC(12, 2) NULL,
  vol_delta_healthy BOOLEAN NULL,
  cvd_slope NUMERIC(10, 6) NULL,
  cvd_slope_healthy BOOLEAN NULL,
  
  -- PRICE/SMA FACTORS (3 points possible)
  sma9 NUMERIC(12, 4) NULL,
  sma21 NUMERIC(12, 4) NULL,
  sma_spread NUMERIC(12, 4) NULL,
  sma_alignment VARCHAR(10) NULL,
  sma_alignment_healthy BOOLEAN NULL,
  sma_momentum NUMERIC(10, 6) NULL,
  sma_momentum_label VARCHAR(15) NULL,
  sma_momentum_healthy BOOLEAN NULL,
  vwap NUMERIC(12, 4) NULL,
  vwap_position VARCHAR(10) NULL,
  vwap_healthy BOOLEAN NULL,
  
  -- COMPOSITE HEALTH SCORE
  health_score INTEGER NULL,
  health_label VARCHAR(15) NULL,
  
  -- FACTOR GROUP SUMMARIES
  structure_score INTEGER NULL,
  volume_score INTEGER NULL,
  price_score INTEGER NULL,
  
  -- METADATA
  bars_used INTEGER NULL,
  calculation_version VARCHAR(10) NULL DEFAULT '1.0',
  calculated_at TIMESTAMPTZ NULL DEFAULT NOW(),
  updated_at TIMESTAMPTZ NULL DEFAULT NOW(),
  
  -- CONSTRAINTS
  CONSTRAINT entry_indicators_pkey PRIMARY KEY (trade_id),
  CONSTRAINT entry_indicators_trade_id_fkey FOREIGN KEY (trade_id) 
    REFERENCES trades (trade_id) ON DELETE CASCADE
) TABLESPACE pg_default;
"""

CREATE_INDEXES_SQL = """
-- Standard filters
CREATE INDEX IF NOT EXISTS idx_ei_date ON public.entry_indicators USING btree (date DESC);
CREATE INDEX IF NOT EXISTS idx_ei_ticker ON public.entry_indicators USING btree (ticker);
CREATE INDEX IF NOT EXISTS idx_ei_model ON public.entry_indicators USING btree (model);
CREATE INDEX IF NOT EXISTS idx_ei_direction ON public.entry_indicators USING btree (direction);
CREATE INDEX IF NOT EXISTS idx_ei_health_score ON public.entry_indicators USING btree (health_score);

-- Composite indexes for common queries
CREATE INDEX IF NOT EXISTS idx_ei_ticker_date ON public.entry_indicators USING btree (ticker, date DESC);
CREATE INDEX IF NOT EXISTS idx_ei_model_direction ON public.entry_indicators USING btree (model, direction);
CREATE INDEX IF NOT EXISTS idx_ei_date_model ON public.entry_indicators USING btree (date, model);
CREATE INDEX IF NOT EXISTS idx_ei_model_health ON public.entry_indicators USING btree (model, health_score);
CREATE INDEX IF NOT EXISTS idx_ei_direction_health ON public.entry_indicators USING btree (direction, health_score);

-- Factor group indexes
CREATE INDEX IF NOT EXISTS idx_ei_structure_score ON public.entry_indicators USING btree (structure_score);
CREATE INDEX IF NOT EXISTS idx_ei_volume_score ON public.entry_indicators USING btree (volume_score);
CREATE INDEX IF NOT EXISTS idx_ei_price_score ON public.entry_indicators USING btree (price_score);
"""

CREATE_TRIGGER_SQL = """
CREATE OR REPLACE TRIGGER update_entry_indicators_updated_at 
  BEFORE UPDATE ON entry_indicators 
  FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
"""

DROP_TABLE_SQL = """
DROP TABLE IF EXISTS public.entry_indicators CASCADE;
"""


def create_table(cursor, conn):
    """Create the entry_indicators table with indexes and trigger."""
    try:
        print("Creating entry_indicators table...")
        cursor.execute(CREATE_TABLE_SQL)
        conn.commit()
        print("✓ Table created")
        
        print("Creating indexes...")
        cursor.execute(CREATE_INDEXES_SQL)
        conn.commit()
        print("✓ Indexes created")
        
        print("Creating trigger...")
        cursor.execute(CREATE_TRIGGER_SQL)
        conn.commit()
        print("✓ Trigger created")
        
        return True
    except Exception as e:
        conn.rollback()
        print(f"✗ Error creating table: {e}")
        return False


def drop_table(cursor, conn):
    """Drop the entry_indicators table."""
    try:
        cursor.execute(DROP_TABLE_SQL)
        conn.commit()
        print("✓ Table dropped")
        return True
    except Exception as e:
        conn.rollback()
        print(f"✗ Error dropping table: {e}")
        return False


def table_exists(cursor) -> bool:
    """Check if entry_indicators table exists."""
    cursor.execute("""
        SELECT EXISTS (
            SELECT FROM information_schema.tables 
            WHERE table_schema = 'public' 
            AND table_name = 'entry_indicators'
        );
    """)
    return cursor.fetchone()[0]
```

---

## 4. INDICATOR CALCULATOR

### File: calculations/indicator_analysis/entry_indicators/calculator.py

```python
"""
Entry Indicators Calculator

Calculates all 10 Health Score factors at the M1 bar prior to entry.
Uses M5+ aggregated data for indicator calculations.
"""

import sys
from pathlib import Path
from datetime import date, time, datetime, timedelta
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
import numpy as np

# Add project root to path for imports
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from config import INDICATOR_ANALYSIS_CONFIG

# Import existing indicator calculations
from calculations.indicators.sma import calculate_sma_spread, calculate_sma_momentum
from calculations.indicators.vwap import calculate_vwap_metrics
from calculations.indicators.volume_roc import calculate_volume_roc
from calculations.indicators.volume_delta import calculate_rolling_delta
from calculations.indicators.cvd import calculate_cvd_slope


@dataclass
class EntryIndicators:
    """Container for all entry indicator values."""
    # Trade context
    trade_id: str
    date: date
    ticker: str
    direction: str
    model: str
    entry_time: time
    entry_price: float
    
    # Indicator bar reference
    indicator_bar_time: Optional[time] = None
    indicator_methodology: str = 'M1_PRIOR'
    
    # Structure factors
    h4_structure: Optional[str] = None
    h4_structure_healthy: Optional[bool] = None
    h1_structure: Optional[str] = None
    h1_structure_healthy: Optional[bool] = None
    m15_structure: Optional[str] = None
    m15_structure_healthy: Optional[bool] = None
    m5_structure: Optional[str] = None
    m5_structure_healthy: Optional[bool] = None
    
    # Volume factors
    vol_roc: Optional[float] = None
    vol_roc_healthy: Optional[bool] = None
    vol_delta: Optional[float] = None
    vol_delta_healthy: Optional[bool] = None
    cvd_slope: Optional[float] = None
    cvd_slope_healthy: Optional[bool] = None
    
    # Price/SMA factors
    sma9: Optional[float] = None
    sma21: Optional[float] = None
    sma_spread: Optional[float] = None
    sma_alignment: Optional[str] = None
    sma_alignment_healthy: Optional[bool] = None
    sma_momentum: Optional[float] = None
    sma_momentum_label: Optional[str] = None
    sma_momentum_healthy: Optional[bool] = None
    vwap: Optional[float] = None
    vwap_position: Optional[str] = None
    vwap_healthy: Optional[bool] = None
    
    # Composite scores
    health_score: Optional[int] = None
    health_label: Optional[str] = None
    structure_score: Optional[int] = None
    volume_score: Optional[int] = None
    price_score: Optional[int] = None
    
    # Metadata
    bars_used: Optional[int] = None
    calculation_version: str = '1.0'
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for database insertion."""
        return {
            'trade_id': self.trade_id,
            'date': self.date,
            'ticker': self.ticker,
            'direction': self.direction,
            'model': self.model,
            'entry_time': self.entry_time,
            'entry_price': self.entry_price,
            'indicator_bar_time': self.indicator_bar_time,
            'indicator_methodology': self.indicator_methodology,
            'h4_structure': self.h4_structure,
            'h4_structure_healthy': self.h4_structure_healthy,
            'h1_structure': self.h1_structure,
            'h1_structure_healthy': self.h1_structure_healthy,
            'm15_structure': self.m15_structure,
            'm15_structure_healthy': self.m15_structure_healthy,
            'm5_structure': self.m5_structure,
            'm5_structure_healthy': self.m5_structure_healthy,
            'vol_roc': self.vol_roc,
            'vol_roc_healthy': self.vol_roc_healthy,
            'vol_delta': self.vol_delta,
            'vol_delta_healthy': self.vol_delta_healthy,
            'cvd_slope': self.cvd_slope,
            'cvd_slope_healthy': self.cvd_slope_healthy,
            'sma9': self.sma9,
            'sma21': self.sma21,
            'sma_spread': self.sma_spread,
            'sma_alignment': self.sma_alignment,
            'sma_alignment_healthy': self.sma_alignment_healthy,
            'sma_momentum': self.sma_momentum,
            'sma_momentum_label': self.sma_momentum_label,
            'sma_momentum_healthy': self.sma_momentum_healthy,
            'vwap': self.vwap,
            'vwap_position': self.vwap_position,
            'vwap_healthy': self.vwap_healthy,
            'health_score': self.health_score,
            'health_label': self.health_label,
            'structure_score': self.structure_score,
            'volume_score': self.volume_score,
            'price_score': self.price_score,
            'bars_used': self.bars_used,
            'calculation_version': self.calculation_version,
        }


def find_last_complete_m1_bar(m1_bars: List[Dict], entry_time: time) -> Optional[Dict]:
    """
    Find the M1 bar that closed just before entry.
    
    M1 bar timestamps are bar OPEN time.
    - 09:38:00 bar covers 09:38:00 - 09:38:59
    
    For entry at 09:39:15, we want the LAST COMPLETE bar = 09:38:00
    """
    entry_seconds = entry_time.hour * 3600 + entry_time.minute * 60 + entry_time.second
    
    last_complete_bar = None
    for bar in m1_bars:
        bar_time = bar.get('timestamp') or bar.get('time')
        if isinstance(bar_time, str):
            bar_time = datetime.fromisoformat(bar_time).time()
        elif isinstance(bar_time, datetime):
            bar_time = bar_time.time()
            
        bar_seconds = bar_time.hour * 3600 + bar_time.minute * 60
        bar_close_seconds = bar_seconds + 60  # Bar closes 60 seconds later
        
        if bar_close_seconds <= entry_seconds:
            last_complete_bar = bar
        else:
            break
    
    return last_complete_bar


def aggregate_m1_to_m5(m1_bars: List[Dict], up_to_time: time) -> List[Dict]:
    """
    Aggregate M1 bars into M5 bars up to the specified time.
    
    M5 bars start at :00, :05, :10, etc.
    """
    if not m1_bars:
        return []
    
    up_to_seconds = up_to_time.hour * 3600 + up_to_time.minute * 60 + up_to_time.second
    
    # Filter bars up to the cutoff time
    filtered_bars = []
    for bar in m1_bars:
        bar_time = bar.get('timestamp') or bar.get('time')
        if isinstance(bar_time, str):
            bar_time = datetime.fromisoformat(bar_time).time()
        elif isinstance(bar_time, datetime):
            bar_time = bar_time.time()
        
        bar_seconds = bar_time.hour * 3600 + bar_time.minute * 60
        if bar_seconds + 60 <= up_to_seconds:  # Bar must be complete
            filtered_bars.append({**bar, 'parsed_time': bar_time})
    
    if not filtered_bars:
        return []
    
    # Group into M5 buckets
    m5_buckets = {}
    for bar in filtered_bars:
        bar_time = bar['parsed_time']
        # M5 bucket: floor to nearest 5 minutes
        bucket_minute = (bar_time.minute // 5) * 5
        bucket_key = f"{bar_time.hour:02d}:{bucket_minute:02d}"
        
        if bucket_key not in m5_buckets:
            m5_buckets[bucket_key] = []
        m5_buckets[bucket_key].append(bar)
    
    # Aggregate each bucket
    m5_bars = []
    for bucket_key in sorted(m5_buckets.keys()):
        bars = m5_buckets[bucket_key]
        if len(bars) < 5:  # Incomplete M5 bar
            continue
            
        m5_bar = {
            'time': bucket_key,
            'open': bars[0].get('open') or bars[0].get('o'),
            'high': max(b.get('high') or b.get('h') for b in bars),
            'low': min(b.get('low') or b.get('l') for b in bars),
            'close': bars[-1].get('close') or bars[-1].get('c'),
            'volume': sum(b.get('volume') or b.get('v') or 0 for b in bars),
        }
        m5_bars.append(m5_bar)
    
    return m5_bars


def is_structure_aligned(structure: str, direction: str) -> bool:
    """Check if structure is aligned with trade direction."""
    if direction == 'LONG':
        return structure == 'BULL'
    else:  # SHORT
        return structure == 'BEAR'


def is_delta_aligned(delta: float, direction: str) -> bool:
    """Check if volume delta is aligned with trade direction."""
    if direction == 'LONG':
        return delta > 0
    else:  # SHORT
        return delta < 0


def is_cvd_aligned(cvd_slope: float, direction: str) -> bool:
    """Check if CVD slope is aligned with trade direction."""
    thresholds = INDICATOR_ANALYSIS_CONFIG['indicator_thresholds']
    if direction == 'LONG':
        return cvd_slope > thresholds['cvd_slope_bullish']
    else:  # SHORT
        return cvd_slope < thresholds['cvd_slope_bearish']


def is_sma_aligned(sma9: float, sma21: float, direction: str) -> bool:
    """Check if SMA alignment matches trade direction."""
    if direction == 'LONG':
        return sma9 > sma21
    else:  # SHORT
        return sma9 < sma21


def is_vwap_aligned(price: float, vwap: float, direction: str) -> bool:
    """Check if price position relative to VWAP matches direction."""
    if direction == 'LONG':
        return price > vwap
    else:  # SHORT
        return price < vwap


def get_health_label(score: int) -> str:
    """Convert health score to label."""
    buckets = INDICATOR_ANALYSIS_CONFIG['health_buckets']
    for label, (low, high) in buckets.items():
        if low <= score <= high:
            return label
    return 'UNKNOWN'


def calculate_entry_indicators(
    trade: Dict,
    m1_bars: List[Dict],
    m5_bars: Optional[List[Dict]] = None,
    m15_bars: Optional[List[Dict]] = None,
    h1_bars: Optional[List[Dict]] = None,
    h4_bars: Optional[List[Dict]] = None
) -> EntryIndicators:
    """
    Calculate all entry indicators for a single trade.
    
    Parameters:
        trade: Trade record from mfe_mae_potential
        m1_bars: M1 bars for the ticker-date
        m5_bars: Optional pre-aggregated M5 bars
        m15_bars: M15 bars for structure detection
        h1_bars: H1 bars for structure detection
        h4_bars: H4 bars for structure detection
    
    Returns:
        EntryIndicators dataclass with all calculated values
    """
    # Initialize result
    result = EntryIndicators(
        trade_id=trade['trade_id'],
        date=trade['date'],
        ticker=trade['ticker'],
        direction=trade['direction'],
        model=trade.get('model'),
        entry_time=trade['entry_time'],
        entry_price=float(trade['entry_price']),
    )
    
    # Find the M1 bar prior to entry
    indicator_bar = find_last_complete_m1_bar(m1_bars, trade['entry_time'])
    if indicator_bar:
        bar_time = indicator_bar.get('timestamp') or indicator_bar.get('time')
        if isinstance(bar_time, str):
            bar_time = datetime.fromisoformat(bar_time).time()
        elif isinstance(bar_time, datetime):
            bar_time = bar_time.time()
        result.indicator_bar_time = bar_time
    
    # Aggregate M1 to M5 if not provided
    if m5_bars is None:
        m5_bars = aggregate_m1_to_m5(m1_bars, trade['entry_time'])
    
    result.bars_used = len(m5_bars)
    
    if len(m5_bars) < 21:  # Need at least 21 bars for SMA21
        return result
    
    # Calculate SMA indicators
    try:
        sma_result = calculate_sma_spread(m5_bars, len(m5_bars) - 1)
        if sma_result:
            result.sma9 = sma_result.sma9
            result.sma21 = sma_result.sma21
            result.sma_spread = sma_result.spread
            result.sma_alignment = sma_result.alignment
            result.sma_alignment_healthy = is_sma_aligned(
                sma_result.sma9, sma_result.sma21, trade['direction']
            )
        
        momentum_result = calculate_sma_momentum(m5_bars, len(m5_bars) - 1)
        if momentum_result:
            result.sma_momentum = momentum_result.ratio
            result.sma_momentum_label = momentum_result.momentum
            result.sma_momentum_healthy = momentum_result.ratio > INDICATOR_ANALYSIS_CONFIG['indicator_thresholds']['sma_widening']
    except Exception as e:
        print(f"SMA calculation error for {trade['trade_id']}: {e}")
    
    # Calculate VWAP
    try:
        vwap_result = calculate_vwap_metrics(m5_bars, len(m5_bars) - 1, result.entry_price)
        if vwap_result:
            result.vwap = vwap_result.vwap
            result.vwap_position = vwap_result.side
            result.vwap_healthy = is_vwap_aligned(
                result.entry_price, vwap_result.vwap, trade['direction']
            )
    except Exception as e:
        print(f"VWAP calculation error for {trade['trade_id']}: {e}")
    
    # Calculate Volume ROC
    try:
        vol_roc_result = calculate_volume_roc(m5_bars, len(m5_bars) - 1)
        if vol_roc_result:
            result.vol_roc = vol_roc_result.roc
            result.vol_roc_healthy = vol_roc_result.roc > INDICATOR_ANALYSIS_CONFIG['indicator_thresholds']['vol_roc']
    except Exception as e:
        print(f"Volume ROC calculation error for {trade['trade_id']}: {e}")
    
    # Calculate Volume Delta
    try:
        delta_result = calculate_rolling_delta(m5_bars, len(m5_bars) - 1)
        if delta_result:
            result.vol_delta = delta_result.rolling_delta
            result.vol_delta_healthy = is_delta_aligned(
                delta_result.rolling_delta, trade['direction']
            )
    except Exception as e:
        print(f"Volume Delta calculation error for {trade['trade_id']}: {e}")
    
    # Calculate CVD Slope
    try:
        cvd_result = calculate_cvd_slope(m5_bars, len(m5_bars) - 1)
        if cvd_result:
            result.cvd_slope = cvd_result.slope
            result.cvd_slope_healthy = is_cvd_aligned(
                cvd_result.slope, trade['direction']
            )
    except Exception as e:
        print(f"CVD calculation error for {trade['trade_id']}: {e}")
    
    # Calculate Structure (placeholder - requires HTF bars)
    # TODO: Implement structure detection when HTF bars available
    # For now, set to None and calculate in Phase 2
    
    # Calculate composite scores
    structure_factors = [
        result.h4_structure_healthy,
        result.h1_structure_healthy,
        result.m15_structure_healthy,
        result.m5_structure_healthy
    ]
    volume_factors = [
        result.vol_roc_healthy,
        result.vol_delta_healthy,
        result.cvd_slope_healthy
    ]
    price_factors = [
        result.sma_alignment_healthy,
        result.sma_momentum_healthy,
        result.vwap_healthy
    ]
    
    result.structure_score = sum(1 for f in structure_factors if f is True)
    result.volume_score = sum(1 for f in volume_factors if f is True)
    result.price_score = sum(1 for f in price_factors if f is True)
    
    result.health_score = result.structure_score + result.volume_score + result.price_score
    result.health_label = get_health_label(result.health_score)
    
    return result
```

---

## 5. DATABASE POPULATOR

### File: calculations/indicator_analysis/entry_indicators/populator.py

```python
"""
Entry Indicators Populator

Populates the entry_indicators table from mfe_mae_potential trades.
Fetches M1 bars from Polygon and calculates indicators.
"""

import sys
from pathlib import Path
from datetime import date, datetime, timedelta
from typing import Dict, List, Optional, Tuple
import time as time_module

project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from data.supabase_client import get_client
from data.polygon_fetcher import PolygonFetcher  # Assumes existing fetcher
from .calculator import calculate_entry_indicators, EntryIndicators


class EntryIndicatorsPopulator:
    """Populates entry_indicators table from trade data."""
    
    def __init__(self):
        self.db_client = get_client()
        self.polygon = PolygonFetcher()
        self.batch_size = 100
        self.api_delay = 0.15  # Respect Polygon rate limits
        
    def get_trades_to_process(
        self,
        date_from: Optional[date] = None,
        date_to: Optional[date] = None,
        force_recalculate: bool = False
    ) -> List[Dict]:
        """
        Get trades from mfe_mae_potential that need indicator calculation.
        
        Parameters:
            date_from: Start date filter
            date_to: End date filter
            force_recalculate: If True, recalculate all trades
        
        Returns:
            List of trade records to process
        """
        query = """
            SELECT mp.*
            FROM mfe_mae_potential mp
        """
        
        if not force_recalculate:
            query += """
            LEFT JOIN entry_indicators ei ON mp.trade_id = ei.trade_id
            WHERE ei.trade_id IS NULL
            """
            where_added = True
        else:
            where_added = False
        
        params = []
        param_idx = 1
        
        if date_from:
            if where_added:
                query += f" AND mp.date >= ${param_idx}"
            else:
                query += f" WHERE mp.date >= ${param_idx}"
                where_added = True
            params.append(date_from)
            param_idx += 1
            
        if date_to:
            if where_added:
                query += f" AND mp.date <= ${param_idx}"
            else:
                query += f" WHERE mp.date <= ${param_idx}"
            params.append(date_to)
            param_idx += 1
        
        query += " ORDER BY mp.date, mp.ticker"
        
        self.db_client.cursor.execute(query, params)
        columns = [desc[0] for desc in self.db_client.cursor.description]
        rows = self.db_client.cursor.fetchall()
        
        return [dict(zip(columns, row)) for row in rows]
    
    def group_trades_by_ticker_date(
        self, 
        trades: List[Dict]
    ) -> Dict[Tuple[str, date], List[Dict]]:
        """Group trades by ticker-date for efficient API calls."""
        groups = {}
        for trade in trades:
            key = (trade['ticker'], trade['date'])
            if key not in groups:
                groups[key] = []
            groups[key].append(trade)
        return groups
    
    def fetch_m1_bars(self, ticker: str, trade_date: date) -> List[Dict]:
        """
        Fetch M1 bars for a ticker-date from Polygon.
        
        Fetches from market open (09:30) to market close (16:00).
        """
        try:
            # Convert date to timestamps
            start_dt = datetime.combine(trade_date, datetime.min.time().replace(hour=9, minute=30))
            end_dt = datetime.combine(trade_date, datetime.min.time().replace(hour=16, minute=0))
            
            bars = self.polygon.get_aggregates(
                ticker=ticker,
                multiplier=1,
                timespan='minute',
                from_date=start_dt,
                to_date=end_dt
            )
            
            time_module.sleep(self.api_delay)  # Rate limit
            return bars
            
        except Exception as e:
            print(f"Error fetching M1 bars for {ticker} on {trade_date}: {e}")
            return []
    
    def insert_indicator_record(self, indicators: EntryIndicators) -> bool:
        """Insert a single indicator record into the database."""
        try:
            data = indicators.to_dict()
            
            columns = list(data.keys())
            placeholders = [f"${i+1}" for i in range(len(columns))]
            values = list(data.values())
            
            query = f"""
                INSERT INTO entry_indicators ({', '.join(columns)})
                VALUES ({', '.join(placeholders)})
                ON CONFLICT (trade_id) DO UPDATE SET
                    {', '.join(f"{col} = EXCLUDED.{col}" for col in columns if col != 'trade_id')},
                    updated_at = NOW()
            """
            
            self.db_client.cursor.execute(query, values)
            self.db_client.conn.commit()
            return True
            
        except Exception as e:
            self.db_client.conn.rollback()
            print(f"Error inserting indicators for {indicators.trade_id}: {e}")
            return False
    
    def insert_batch(self, indicators_list: List[EntryIndicators]) -> Tuple[int, int]:
        """
        Insert a batch of indicator records.
        
        Returns:
            Tuple of (success_count, failure_count)
        """
        success = 0
        failure = 0
        
        for indicators in indicators_list:
            if self.insert_indicator_record(indicators):
                success += 1
            else:
                failure += 1
        
        return success, failure
    
    def populate(
        self,
        date_from: Optional[date] = None,
        date_to: Optional[date] = None,
        force_recalculate: bool = False,
        verbose: bool = True
    ) -> Dict[str, int]:
        """
        Main population method.
        
        Parameters:
            date_from: Start date filter
            date_to: End date filter
            force_recalculate: If True, recalculate existing records
            verbose: Print progress updates
        
        Returns:
            Dictionary with success/failure counts
        """
        # Get trades to process
        trades = self.get_trades_to_process(date_from, date_to, force_recalculate)
        
        if not trades:
            if verbose:
                print("No trades to process.")
            return {'processed': 0, 'success': 0, 'failure': 0}
        
        if verbose:
            print(f"Found {len(trades)} trades to process")
        
        # Group by ticker-date for efficient API calls
        groups = self.group_trades_by_ticker_date(trades)
        
        if verbose:
            print(f"Grouped into {len(groups)} ticker-date combinations")
        
        total_success = 0
        total_failure = 0
        processed = 0
        
        for (ticker, trade_date), group_trades in groups.items():
            if verbose:
                print(f"\nProcessing {ticker} on {trade_date} ({len(group_trades)} trades)...")
            
            # Fetch M1 bars for this ticker-date
            m1_bars = self.fetch_m1_bars(ticker, trade_date)
            
            if not m1_bars:
                if verbose:
                    print(f"  ⚠ No M1 bars available, skipping")
                total_failure += len(group_trades)
                continue
            
            # Calculate indicators for each trade
            indicators_batch = []
            for trade in group_trades:
                try:
                    indicators = calculate_entry_indicators(trade, m1_bars)
                    indicators_batch.append(indicators)
                except Exception as e:
                    if verbose:
                        print(f"  ✗ Error calculating {trade['trade_id']}: {e}")
                    total_failure += 1
            
            # Insert batch
            if indicators_batch:
                success, failure = self.insert_batch(indicators_batch)
                total_success += success
                total_failure += failure
                
                if verbose:
                    print(f"  ✓ Inserted {success}, failed {failure}")
            
            processed += len(group_trades)
            
            if verbose and processed % 100 == 0:
                print(f"\n--- Progress: {processed}/{len(trades)} trades ---")
        
        results = {
            'processed': processed,
            'success': total_success,
            'failure': total_failure
        }
        
        if verbose:
            print(f"\n{'='*50}")
            print(f"Population complete:")
            print(f"  Processed: {results['processed']}")
            print(f"  Success: {results['success']}")
            print(f"  Failure: {results['failure']}")
        
        return results
```

---

## 6. CLI RUNNER

### File: calculations/indicator_analysis/entry_indicators/runner.py

```python
"""
Entry Indicators Runner

CLI entry point for managing the entry_indicators table.

Usage:
    python -m calculations.indicator_analysis.entry_indicators.runner --action create
    python -m calculations.indicator_analysis.entry_indicators.runner --action populate
    python -m calculations.indicator_analysis.entry_indicators.runner --action populate --date-from 2025-12-15
    python -m calculations.indicator_analysis.entry_indicators.runner --action drop
    python -m calculations.indicator_analysis.entry_indicators.runner --action status
"""

import argparse
import sys
from pathlib import Path
from datetime import datetime

project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from data.supabase_client import get_client
from .table_schema import create_table, drop_table, table_exists
from .populator import EntryIndicatorsPopulator


def parse_date(date_str: str):
    """Parse date string to date object."""
    return datetime.strptime(date_str, '%Y-%m-%d').date()


def action_create():
    """Create the entry_indicators table."""
    client = get_client()
    
    if table_exists(client.cursor):
        print("Table entry_indicators already exists.")
        response = input("Drop and recreate? (y/n): ")
        if response.lower() == 'y':
            drop_table(client.cursor, client.conn)
            create_table(client.cursor, client.conn)
        else:
            print("Aborted.")
    else:
        create_table(client.cursor, client.conn)


def action_drop():
    """Drop the entry_indicators table."""
    client = get_client()
    
    if not table_exists(client.cursor):
        print("Table entry_indicators does not exist.")
        return
    
    response = input("Are you sure you want to drop entry_indicators? (y/n): ")
    if response.lower() == 'y':
        drop_table(client.cursor, client.conn)
    else:
        print("Aborted.")


def action_populate(date_from=None, date_to=None, force=False):
    """Populate the entry_indicators table."""
    client = get_client()
    
    if not table_exists(client.cursor):
        print("Table entry_indicators does not exist. Run --action create first.")
        return
    
    populator = EntryIndicatorsPopulator()
    populator.populate(
        date_from=date_from,
        date_to=date_to,
        force_recalculate=force,
        verbose=True
    )


def action_status():
    """Show status of entry_indicators table."""
    client = get_client()
    
    if not table_exists(client.cursor):
        print("Table entry_indicators does not exist.")
        return
    
    # Count records
    client.cursor.execute("SELECT COUNT(*) FROM entry_indicators")
    total = client.cursor.fetchone()[0]
    
    # Count by model
    client.cursor.execute("""
        SELECT model, COUNT(*) 
        FROM entry_indicators 
        GROUP BY model 
        ORDER BY model
    """)
    by_model = client.cursor.fetchall()
    
    # Date range
    client.cursor.execute("""
        SELECT MIN(date), MAX(date) 
        FROM entry_indicators
    """)
    date_range = client.cursor.fetchone()
    
    # Trades needing population
    client.cursor.execute("""
        SELECT COUNT(*) 
        FROM mfe_mae_potential mp
        LEFT JOIN entry_indicators ei ON mp.trade_id = ei.trade_id
        WHERE ei.trade_id IS NULL
    """)
    pending = client.cursor.fetchone()[0]
    
    print("\n" + "="*50)
    print("ENTRY INDICATORS TABLE STATUS")
    print("="*50)
    print(f"\nTotal Records: {total}")
    print(f"Pending Population: {pending}")
    
    if date_range[0]:
        print(f"Date Range: {date_range[0]} to {date_range[1]}")
    
    print("\nBy Model:")
    for model, count in by_model:
        print(f"  {model}: {count}")
    
    print("="*50)


def main():
    parser = argparse.ArgumentParser(
        description='Entry Indicators Table Management'
    )
    parser.add_argument(
        '--action',
        choices=['create', 'drop', 'populate', 'status'],
        required=True,
        help='Action to perform'
    )
    parser.add_argument(
        '--date-from',
        type=parse_date,
        help='Start date for population (YYYY-MM-DD)'
    )
    parser.add_argument(
        '--date-to',
        type=parse_date,
        help='End date for population (YYYY-MM-DD)'
    )
    parser.add_argument(
        '--force',
        action='store_true',
        help='Force recalculation of existing records'
    )
    
    args = parser.parse_args()
    
    if args.action == 'create':
        action_create()
    elif args.action == 'drop':
        action_drop()
    elif args.action == 'populate':
        action_populate(args.date_from, args.date_to, args.force)
    elif args.action == 'status':
        action_status()


if __name__ == '__main__':
    main()
```

---

## 7. MODULE __init__.py

### File: calculations/indicator_analysis/entry_indicators/__init__.py

```python
"""
Entry Indicators Module

Manages the entry_indicators table and provides calculation utilities.

Usage:
    from calculations.indicator_analysis.entry_indicators import (
        EntryIndicatorsPopulator,
        calculate_entry_indicators,
        EntryIndicators
    )
"""

from .calculator import (
    EntryIndicators,
    calculate_entry_indicators,
    find_last_complete_m1_bar,
    aggregate_m1_to_m5
)
from .populator import EntryIndicatorsPopulator
from .table_schema import create_table, drop_table, table_exists

__all__ = [
    'EntryIndicators',
    'calculate_entry_indicators',
    'find_last_complete_m1_bar',
    'aggregate_m1_to_m5',
    'EntryIndicatorsPopulator',
    'create_table',
    'drop_table',
    'table_exists'
]
```

---

## 8. FILE CREATION SUMMARY

| File | Purpose |
|------|---------|
| `calculations/indicator_analysis/entry_indicators/__init__.py` | Module exports |
| `calculations/indicator_analysis/entry_indicators/table_schema.py` | SQL schema and DDL |
| `calculations/indicator_analysis/entry_indicators/calculator.py` | Indicator calculation logic |
| `calculations/indicator_analysis/entry_indicators/populator.py` | Database population |
| `calculations/indicator_analysis/entry_indicators/runner.py` | CLI interface |

---

## 9. VERIFICATION STEPS

After implementation:

1. **Create table:**
   ```bash
   cd C:\XIIITradingSystems\Epoch\02_zone_system\12_indicator_analysis
   python -m calculations.indicator_analysis.entry_indicators.runner --action create
   ```

2. **Check status:**
   ```bash
   python -m calculations.indicator_analysis.entry_indicators.runner --action status
   ```

3. **Populate (test with date range):**
   ```bash
   python -m calculations.indicator_analysis.entry_indicators.runner --action populate --date-from 2025-12-15 --date-to 2025-12-16
   ```

4. **Verify in Supabase:**
   ```sql
   SELECT * FROM entry_indicators LIMIT 10;
   ```

---

## 10. NOTES FOR CLAUDE CODE

1. **Polygon Fetcher**: Assumes existing `data/polygon_fetcher.py` with `get_aggregates()` method. Adapt if interface differs.

2. **Structure Calculation**: Structure detection (M5/M15/H1/H4) requires additional HTF bars. Currently returns None - Phase 2 will add HTF fetching.

3. **Rate Limiting**: 0.15s delay between Polygon calls. Adjust based on subscription tier.

4. **Error Handling**: Individual trade failures don't stop batch processing. Check logs for issues.

5. **Idempotency**: Uses `ON CONFLICT DO UPDATE` for safe re-runs.

---

**END OF DOCUMENT 2**